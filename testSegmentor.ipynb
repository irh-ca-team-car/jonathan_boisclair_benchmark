{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boiscljo/git/a3r/interface/impl/EffDet/model.py:16: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import fiftyone\n",
    "import fiftyone.zoo\n",
    "from interface.segmentation.Segmenter import Segmenter\n",
    "\n",
    "lraspp = Segmenter.named(\"lraspp_mobilenet_v3_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<interface.datasets.Sample.Sample at 0x7fa56c18e100>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from interface.datasets.Sample import Sample\n",
    "img = Sample()\n",
    "img.setImage(torch.randn(3,200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /io/opencv/modules/core/src/copy.cpp:1026: error: (-215:Assertion failed) top >= 0 && bottom >= 0 && left >= 0 && right >= 0 && _src.dims() <= 2 in function 'copyMakeBorder'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/home/boiscljo/git/a3r/testSegmentor.ipynb Cell 3\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/boiscljo/git/a3r/testSegmentor.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prediction \u001b[39m=\u001b[39m lraspp\u001b[39m.\u001b[39;49mforward([img,img])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/boiscljo/git/a3r/testSegmentor.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(prediction)\n",
      "File \u001b[0;32m~/git/a3r/interface/segmentation/Segmenter.py:35\u001b[0m, in \u001b[0;36mSegmenter.forward\u001b[0;34m(self, x, target, dataset)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward([v\u001b[39m.\u001b[39mgetGray() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m x],[v\u001b[39m.\u001b[39mgetLidar() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m x],[v\u001b[39m.\u001b[39mgetThermal() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m x],target, dataset\u001b[39m=\u001b[39mdataset)\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_channel \u001b[39m==\u001b[39m\u001b[39m3\u001b[39m :\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward([v\u001b[39m.\u001b[39;49mgetRGB() \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m x],[v\u001b[39m.\u001b[39;49mgetLidar() \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m x],[v\u001b[39m.\u001b[39;49mgetThermal() \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m x],target, dataset\u001b[39m=\u001b[39;49mdataset)\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_channel \u001b[39m==\u001b[39m\u001b[39m4\u001b[39m :\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward([v\u001b[39m.\u001b[39mgetARGB() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m x],[v\u001b[39m.\u001b[39mgetLidar() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m x],[v\u001b[39m.\u001b[39mgetThermal() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m x],target, dataset\u001b[39m=\u001b[39mdataset)\n",
      "File \u001b[0;32m~/git/a3r/interface/segmentation/Segmenter.py:112\u001b[0m, in \u001b[0;36mTorchVisionSegmenter._forward\u001b[0;34m(self, rgb, lidar, thermal, target, dataset)\u001b[0m\n\u001b[1;32m    110\u001b[0m trs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights\u001b[39m.\u001b[39mtransforms()\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rgb,\u001b[39mlist\u001b[39m):\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(torch\u001b[39m.\u001b[39;49mcat([trs(v)\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m rgb],\u001b[39m0\u001b[39;49m), \u001b[39mNone\u001b[39;49;00m,\u001b[39mNone\u001b[39;49;00m, target)\n\u001b[1;32m    113\u001b[0m is_list \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(rgb\u001b[39m.\u001b[39mshape)\u001b[39m==\u001b[39m\u001b[39m3\u001b[39m:\n",
      "File \u001b[0;32m~/git/a3r/interface/segmentation/Segmenter.py:136\u001b[0m, in \u001b[0;36mTorchVisionSegmenter._forward\u001b[0;34m(self, rgb, lidar, thermal, target, dataset)\u001b[0m\n\u001b[1;32m    134\u001b[0m result\u001b[39m=\u001b[39m[]\n\u001b[1;32m    135\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(normalized_masks_2\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m--> 136\u001b[0m     result\u001b[39m.\u001b[39mappend(Segmentation\u001b[39m.\u001b[39;49mFromImage(normalized_masks_2[i], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights\u001b[39m.\u001b[39;49mmeta[\u001b[39m\"\u001b[39;49m\u001b[39mcategories\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list:\n\u001b[1;32m    138\u001b[0m     \u001b[39mreturn\u001b[39;00m result[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/git/a3r/interface/datasets/Sample.py:293\u001b[0m, in \u001b[0;36mSegmentation.FromImage\u001b[0;34m(img, classesName)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39mif\u001b[39;00m clz\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m: \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    292\u001b[0m class_blobs \u001b[39m=\u001b[39m (labels\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint32) \u001b[39m==\u001b[39m clz)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8)\n\u001b[0;32m--> 293\u001b[0m contours, hierarchy \u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39;49mfindContours(class_blobs,cv2\u001b[39m.\u001b[39;49mRETR_EXTERNAL,cv2\u001b[39m.\u001b[39;49mCHAIN_APPROX_NONE)\n\u001b[1;32m    294\u001b[0m \u001b[39mfor\u001b[39;00m contour \u001b[39min\u001b[39;00m contours:\n\u001b[1;32m    295\u001b[0m     nPts \u001b[39m=\u001b[39m contour\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /io/opencv/modules/core/src/copy.cpp:1026: error: (-215:Assertion failed) top >= 0 && bottom >= 0 && left >= 0 && right >= 0 && _src.dims() <= 2 in function 'copyMakeBorder'\n"
     ]
    }
   ],
   "source": [
    "prediction = lraspp.forward([img,img])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
